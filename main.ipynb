{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import numba as nb \n",
    "from tqdm import *\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from my_layer import *\n",
    "import multiprocessing\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"elu\" \n",
    "node_hidden = 300\n",
    "rel_hidden = 300\n",
    "batch_size = 512\n",
    "dropout_rate = 0.3\n",
    "core_num = 16\n",
    "lr = 0.005\n",
    "depth = 2\n",
    "info = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.random.seed(12306)\n",
    "file_path = \"data/fr_en/\"\n",
    "all_triples,node_size,rel_size = load_triples(file_path,True)\n",
    "train_pair,dev_pair = load_aligned_pair(file_path)\n",
    "all_triples,all_ent_ent,all_ent_rel = generate_map(all_triples,node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_obtain_feature():\n",
    "    feature_model.set_weights(train_model.get_weights())\n",
    "    inputs = [[i for i in range(node_size)],all_triples,all_ent_ent,all_ent_rel]\n",
    "    inputs = [np.expand_dims(item,axis=0) for item in inputs]\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        vec = feature_model.predict_on_batch(inputs)\n",
    "    return vec\n",
    "\n",
    "def gather_embeddings(indexs,vec):\n",
    "    def gather(index,vec):\n",
    "        result_vec = np.array([vec[e] for e in index])\n",
    "        result_vec = result_vec / (np.linalg.norm(result_vec,axis=-1,keepdims=True)+1e-6)\n",
    "        return result_vec\n",
    "    return [gather(index,vec) for index in indexs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_model(node_hidden,rel_hidden,n_attn_heads = 2,dropout_rate = 0,lr = 0.005,depth = 2):\n",
    "    used_node = Input(shape=(None,))\n",
    "    input_triples = Input(shape=(None,3))\n",
    "    ent_ent = Input(shape=(None,2))\n",
    "    ent_rel = Input(shape=(None,2))\n",
    "    \n",
    "    ent_emb = TokenEmbedding(node_size,node_hidden)(input_triples)\n",
    "    ent_emb = Lambda(lambda x:K.squeeze(K.gather(indices=K.cast(x[0],\"int32\"),reference=x[1]),axis=0))([used_node,ent_emb])\n",
    "    rel_emb = TokenEmbedding(rel_size,node_hidden)(input_triples)\n",
    "    \n",
    "    def avg(tensor):\n",
    "        adj,emb = tensor; adj = K.squeeze(K.cast(adj,\"int32\"),axis=0)\n",
    "        embeds = K.gather(indices=adj[:,1],reference=emb)\n",
    "        sums = tf.math.segment_sum(segment_ids=adj[:,0],data=tf.ones_like(embeds))\n",
    "        embeds = tf.math.segment_sum(segment_ids=adj[:,0],data=embeds)\n",
    "        return embeds/sums\n",
    "    \n",
    "    ent_feature = Activation(activation)(Lambda(avg)([ent_ent,ent_emb]))\n",
    "    rel_feature = Activation(activation)(Lambda(avg)([ent_rel,rel_emb]))\n",
    "    results = [ent_feature,rel_feature]\n",
    "    for i in range(depth):\n",
    "        encoder = NR_GraphAttention(node_size,\n",
    "                                    rel_size,\n",
    "                                    activation = activation,\n",
    "                                    attn_heads=n_attn_heads,\n",
    "                                    attn_heads_reduction='average')\n",
    "        \n",
    "        ent_feature = encoder([input_triples,ent_feature,rel_emb])\n",
    "        rel_feature = encoder([input_triples,rel_feature,rel_emb])\n",
    "        results.extend([ent_feature,rel_feature])\n",
    "        \n",
    "    \n",
    "    out_feature = Concatenate()(results)\n",
    "    out_feature = Dropout(dropout_rate)(out_feature)\n",
    "    \n",
    "    alignment_input = Input(shape=(None,2))\n",
    "    def gather_pair_emb(tensor):\n",
    "        emb = tensor[1]\n",
    "        l,r = K.cast(tensor[0][0,:,0],'int32'),K.cast(tensor[0][0,:,1],'int32')\n",
    "        l_emb,r_emb = K.gather(reference=emb,indices=l),K.gather(reference=emb,indices=r)\n",
    "        return [l_emb,r_emb]\n",
    "    lemb,remb = Lambda(gather_pair_emb)([alignment_input,out_feature])\n",
    "    \n",
    "    fixed_emb = Input((None,2,None))\n",
    "    fixed_features = Lambda(lambda x:K.squeeze(x,axis=0))(fixed_emb)\n",
    "    fixed_features = Dropout(dropout_rate)(fixed_features)\n",
    "    fixed_lemb,fixed_remb = Lambda(lambda x:[x[:,0,:],x[:,1,:]])(fixed_features)\n",
    "    \n",
    "    def align_loss(tensor): \n",
    "        \n",
    "        def normalize(x):\n",
    "            x = (x-K.mean(x,0))/K.std(x,0)\n",
    "            x = K.l2_normalize(x,axis=-1)\n",
    "            return x\n",
    "        \n",
    "        l_emb,r_emb,fixed_lemb,fixed_remb = [normalize(x) for x in tensor]\n",
    "\n",
    "        lpos_dis = - K.sum(l_emb*fixed_remb,axis=-1)\n",
    "        lpos_dis = K.pow(lpos_dis,3)\n",
    "        \n",
    "        rpos_dis = - K.sum(r_emb*fixed_lemb,axis=-1)\n",
    "        rpos_dis = K.pow(rpos_dis,3)\n",
    "        return K.mean(lpos_dis+rpos_dis,keepdims=True)\n",
    "    \n",
    "    loss = Lambda(align_loss)([lemb,remb,fixed_lemb,fixed_remb])\n",
    "    \n",
    "    inputs = [used_node,input_triples,ent_ent,ent_rel]\n",
    "    train_model = tf.keras.Model(inputs = inputs + [alignment_input,fixed_emb],outputs = loss)\n",
    "    train_model.compile(loss=lambda y_true,y_pred: y_pred,optimizer=tf.keras.optimizers.RMSprop(lr=lr,rho=0.95,centered=True))\n",
    "    \n",
    "    \n",
    "    feature_model = tf.keras.Model(inputs = inputs,outputs = out_feature)\n",
    "    \n",
    "    return train_model,feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model,_ = get_main_model(dropout_rate=dropout_rate,\n",
    "                          n_attn_heads = 1,\n",
    "                          depth=depth,\n",
    "                          node_hidden=node_hidden,\n",
    "                          rel_hidden=rel_hidden,\n",
    "                          lr=lr)\n",
    "\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    _,feature_model = get_main_model(dropout_rate=dropout_rate,\n",
    "                          n_attn_heads = 1,\n",
    "                          depth=depth,\n",
    "                          node_hidden=node_hidden,\n",
    "                          rel_hidden=rel_hidden,\n",
    "                          lr=lr)\n",
    "\n",
    "init_features = update_and_obtain_feature()\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "@nb.njit()\n",
    "def find_start(triples):\n",
    "    adj_dic = {}\n",
    "    for i,(h,r,t) in enumerate(triples):\n",
    "        if h not in adj_dic:\n",
    "            temp = nb.typed.List()\n",
    "            temp.append((r,t))\n",
    "            adj_dic[h] = temp\n",
    "        else:\n",
    "            adj_dic[h].append((r,t))\n",
    "    return adj_dic\n",
    "\n",
    "adj_dic = find_start(all_triples)\n",
    "\n",
    "\n",
    "def bfs(pairs,rel_weights,max_depth,info):\n",
    "    triples,ent_ent,ent_rel,node_dict,used_node = select_path(pairs.flatten(),adj_dic,rel_weights,max_depth,info)\n",
    "    triples = np.unique(triples,axis=0)\n",
    "    mapped_pairs = np.array([i for i in range(pairs.shape[0]*2)]).reshape((-1,2))\n",
    "    fix_emb = np.array([[init_features[i] for i in pair]for pair in pairs])\n",
    "    inputs = [used_node,triples,ent_ent,ent_rel,mapped_pairs,fix_emb]\n",
    "    inputs = [np.array([item]) for item in inputs]\n",
    "    return inputs\n",
    "\n",
    "def generate_batch(train_pair,rel_weights,max_depth,info):\n",
    "    np.random.shuffle(train_pair)\n",
    "    pool = multiprocessing.Pool(processes=core_num)\n",
    "    inputs = []\n",
    "    for i in range(len(train_pair)//batch_size+1):\n",
    "        inputs.append(pool.apply_async(bfs,(train_pair[i*batch_size:(i+1)*batch_size],rel_weights,max_depth,info)))\n",
    "    pool.close()\n",
    "    return inputs,pool\n",
    "\n",
    "rel_weights = np.ones(rel_size,dtype=\"float32\")\n",
    "next_inputs,pool = generate_batch(train_pair,rel_weights,depth+2,info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = {}\n",
    "rest_set_1 = [e1 for e1, e2 in dev_pair]\n",
    "rest_set_2 = [e2 for e1, e2 in dev_pair]\n",
    "np.random.shuffle(rest_set_1)\n",
    "np.random.shuffle(rest_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epoch = 7\n",
    "for turn in range(10):\n",
    "    for i in trange(epoch):\n",
    "        pool.join()\n",
    "        inputs = [res.get() for res in next_inputs]  \n",
    "        weights = train_model.get_weights()\n",
    "        rel_weights = np.squeeze(np.exp(np.dot(weights[1],weights[2])),axis=-1)\n",
    "        next_inputs,pool = generate_batch(train_pair,rel_weights,depth+2,info)\n",
    "        \n",
    "        for _ in range(2):\n",
    "            shuffle(inputs)\n",
    "            for input_batch in inputs:\n",
    "                train_model.train_on_batch(input_batch,np.zeros((1,1)))\n",
    "                \n",
    "        \n",
    "    now_features = update_and_obtain_feature()\n",
    "    Lvec,Rvec = gather_embeddings([dev_pair[:,0],dev_pair[:,1]],now_features)\n",
    "    ILvec,IRvec = gather_embeddings([dev_pair[:,0],dev_pair[:,1]],init_features)\n",
    "    GPU_test(Lvec,IRvec,512)\n",
    "    GPU_test(Rvec,ILvec,512)\n",
    "    \n",
    "    now_features = update_and_obtain_feature()\n",
    "    Lvec,Rvec = gather_embeddings([rest_set_1,rest_set_2],now_features)\n",
    "    ILvec,IRvec = gather_embeddings([rest_set_1,rest_set_2],init_features)\n",
    "    \n",
    "    A = CSLS_cal(Lvec,IRvec,False,512)\n",
    "    B = CSLS_cal(Rvec,ILvec,False,512)\n",
    "    A = np.argmax(A,1)\n",
    "    B = np.argmax(B,1)\n",
    "    \n",
    "    new_pair = []\n",
    "    for i,j in enumerate(A):\n",
    "        if  B[j] == i:\n",
    "            new_pair.append([rest_set_1[j],rest_set_2[i]])\n",
    "\n",
    "    for e1,e2 in new_pair:\n",
    "        if e1 in rest_set_1:\n",
    "            rest_set_1.remove(e1)   \n",
    "        if e2 in rest_set_2:\n",
    "            rest_set_2.remove(e2)\n",
    "            \n",
    "    print(len(new_pair))\n",
    "    \n",
    "    for i,j in dis:\n",
    "        emb_i,emb_j = now_features[i],now_features[j]\n",
    "        now_dis = emb_i.dot(emb_j.T)/(np.linalg.norm(emb_i)*np.linalg.norm(emb_j))\n",
    "        if dis[(i,j)] - now_dis > 0.05:\n",
    "            new_pair.append([i,j])\n",
    "    print(len(new_pair))\n",
    "    \n",
    "    for i,j in train_pair:\n",
    "        emb_i,emb_j = now_features[i],now_features[j]\n",
    "        now_dis = emb_i.dot(emb_j.T)/(np.linalg.norm(emb_i)*np.linalg.norm(emb_j))\n",
    "        dis[(i,j)] = now_dis  \n",
    "    train_pair = np.array(new_pair)\n",
    "    epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6",
   "language": "python",
   "name": "tf2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
